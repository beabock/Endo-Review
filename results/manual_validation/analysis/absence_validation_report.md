
# Absence Validation Analysis Report

Generated on: 2025-11-13

## Summary Statistics
- Total abstracts validated: 102
- Total validators: 1
- Validation period: 9/23/2025 to 9/23/2025

## Manual Label Distribution
|manual_label |  n| percentage|
|:------------|--:|----------:|
|Absence      |  1|  0.9803922|
|Both         | 15| 14.7058824|
|Irrelevant   | 40| 39.2156863|
|Presence     | 46| 45.0980392|

## Detection Method Precision
This table shows the precision of your 'Absence' predictions.
Precision = (Correct 'Absence' labels) / (Total 'Absence' labels checked)
|absence_source_confirmed | total_validated| true_positives| false_positives| precision| false_discovery_rate|
|:------------------------|---------------:|--------------:|---------------:|---------:|--------------------:|
|Training_Manual          |               1|              1|               0|       100|                    0|
|ML                       |              46|              0|              46|         0|                  100|

## Performance by Confidence Level
|manual_confidence | total_cases_ML| total_cases_Training_Manual| precision_ML| precision_Training_Manual|
|:-----------------|--------------:|---------------------------:|------------:|-------------------------:|
|High              |             46|                           1|            0|                       100|

## Key Findings

### Method Effectiveness
|absence_source_confirmed |manual_label |  n| percentage|
|:------------------------|:------------|--:|----------:|
|ML                       |Both         |  4|   4.494382|
|ML                       |Irrelevant   | 39|  43.820225|
|ML                       |Presence     | 46|  51.685393|
|String                   |Both         | 11|  91.666667|
|String                   |Irrelevant   |  1|   8.333333|
|Training_Manual          |Absence      |  1| 100.000000|

### Confidence Analysis
|manual_confidence |manual_label |  n| percentage|
|:-----------------|:------------|--:|----------:|
|High              |Absence      |  1|  0.9803922|
|High              |Both         | 15| 14.7058824|
|High              |Irrelevant   | 40| 39.2156863|
|High              |Presence     | 46| 45.0980392|

### Patterns and Biases
- Detection vs Manual Label Correlation: |absence_source_confirmed | Both| Irrelevant| Presence| Absence|
|:------------------------|----:|----------:|--------:|-------:|
|ML                       |    4|         39|       46|       0|
|String                   |   11|          1|        0|       0|
|Training_Manual          |    0|          0|        0|       1|

### Recommendations
1. **Method Improvements**: The 'ML' detection method has the lowest precision. Focus on improving its logic.
2. **Confidence Review**: Review classifications with 'High' confidence, as they have the lowest precision.
3. **Training Data**: The model incorrectly labeled 'Presence' cases as 'Absence'. Incorporate more of these false positive examples into future training data to improve discrimination.
4. **Quality Control**: Implement double-validation for all 'High' confidence classifications to catch potential errors early.

## Data Quality Notes
- Abstracts with notes/issues: 27
- Average notes length: 12.0 characters
- Irrelevant classifications: 40 (39.2%)

---
## Actionable Insights from Notes
### Notes from ML False Positives
*These are the notes from cases your ML model labeled 'Absence' but were manually corrected to 'Presence'. This is the key to fixing the 0% precision.*

No notes found for ML False Positives.

---
*Report generated by absence_validation_analysis.R*

